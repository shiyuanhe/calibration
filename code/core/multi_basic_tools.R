oneRoundWrap_multi = function(iter){
    numMethod = length(thetaIndexList) + 1
    result = numeric()
    
    for(j in 1:(numMethod -1)){
        thetaIndex <<- thetaIndexList[j]
        getInit <<- getInitList[[j]]
        tmp = oneRoundCore_multi(iter)
        result = rbind(result, tmp)
    }
    
    # Bayesian
    res = oneRound_bayesian(iter)[1,]
    result = rbind(result, res)
    return(result)
}

## One Round of iteration
## Lot of variables should be inside the memory
##    problemIndex, thetaIndex, linkIndex, numComp
##    lowerX, upperX, nSample
##    y_physics() getInit()
##    TrueSeqX, TrueSeqY, TrueSeqTheta
##
## Choice of theta type: 1 const, 2 exp, 3 quadratic, 6 cubic
oneRoundCore_multi = function(iter){
    simuData = y_physics(nSample,lowerB, upperB)
    emuData = y_emulator(lowerB, upperB,linkLowerB, linkUpperB)
    lambdaOpt = 1
    modelObjCC = create_CalibrationObj(problemIndex, 
                                       thetaIndex, linkIndex, numComp, 
                                       emuData, emulator_betaOpt, linkLowerB, linkUpperB)
    modelObjCC$GP_setNugget(nugget)
    modelObjCC$setData(simuData$y, simuData$x, lowerB, upperB)
    

    if(thetaIndex == 5){ ## RKHS has tuning parameter
        res = selectLambdaGCV_multi(modelObjCC, lambdaSeq, getInit, nSample, 
                                    plotcv = FALSE, nTry = nTry_global1)
        lambdaOpt = res$lambdaOpt
        modelObjCC$setLambda(lambdaOpt)
    }
    res = optimize_CalModel_multi(getInit, nSample, modelObjCC, nTry = nTry_global2)
    optGamma = res$par
    ySeqHat = modelObjCC$predict_y(optGamma, TrueSeqX, FALSE)
    ySigma = modelObjCC$sigmaSq_y(optGamma, TrueSeqX,  lambdaOpt)

    error = ComputeThetaLoss(TrueSeqX, TrueSeqY, ySeqHat[,1], ySigma[,1])
    return(error)
}

## Optimize once with initial value gammaInit
optimize_CalModelOnce_multi = function(gammaInit, calObj){
    objWrap = function(x) {
        x = matrix(x, ncol = calObj$getNumComp() )
        return(calObj$objFun(x))
    }
    
    gradWrap = function(x){
        x = matrix(x, ncol = calObj$getNumComp() )
        gradVec = calObj$gradFun(x)
        return(gradVec)#as.vector(gradVec))
    }
    
    result = optim(gammaInit, fn = objWrap, 
                   gr = gradWrap, 
                   method = "BFGS",
                   control = list(maxit = 100))
    
    return(result)
}

## Optimize multiple times (nTry)
## Init values are generated by function getInit
## nSample: sample size
optimize_CalModel_multi = function(getInit, nSample, calObj, nTry){
    optValue = 1e10
    optResult = NULL
    for(i in 1:nTry){
        try({
            gammaInit = getInit(nSample)
            result = optimize_CalModelOnce_multi(gammaInit, calObj)
            if(result$value < optValue){
                optValue = result$value
                optResult = result
            }
        })
    }
    return(optResult)
}



## Select tuning parameter lambda by generalized CV.
## Return the optimal lambda and the last optimizaed gamma.
## The returned gamma can not be used but to optimize again 
## as init value at the selected lambda.
selectLambdaGCV_multi = function(calObjCC, lambdaSeq, getInit, nSample,
                           plotcv = FALSE, nTry = 150){
    
    GCVSeq = rep(0, length(lambdaSeq))
    gammaOpt = NULL
    lambdaOpt = NULL
    
    for(lambdaJ in 1:length(lambdaSeq)){
        #print(lambdaJ)
        calObjCC$setLambda(lambdaSeq[lambdaJ])
        if(lambdaJ == 1){
            ## The first is randomized multiple times
            result = optimize_CalModel_multi(getInit, nSample, calObjCC, nTry = nTry)
        }else{
            result = optimize_CalModelOnce_multi(gammaHat, calObjCC)
        }
        gammaHat = matrix(result$par, ncol = calObjCC$getNumComp() )
        GCVSeq[lambdaJ] = calObjCC$compute_GCV(gammaHat, lambdaSeq[lambdaJ])
    }
    
    ## Normalize GCV, select where the value start to decrease slowly,
    ## as what is done in PCA scree plot
    GCVSeqNd = (GCVSeq - min(GCVSeq)) / (max(GCVSeq) - min(GCVSeq))
    GradND = abs(diff(GCVSeqNd)) ## gradient of nearby points
    GradND = GradND / max(GradND)
    selJ = which.min(abs(GradND - 0.1) ) ## close to 0.2, slow decreas value
    lambdaOpt = lambdaSeq[selJ]
    GCVOpt= GCVSeq[selJ]
    # if plotcv
    if(plotcv){
        plot(log(lambdaSeq), GCVSeq)
        points(log(lambdaOpt), GCVOpt, pch = 20)
    }
    return(list(lambdaOpt = lambdaOpt, gammaLast = gammaHat))
}


